{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cade254",
   "metadata": {},
   "source": [
    "# Homework 3 \n",
    "\n",
    "\n",
    "_Author:_ Muhammed Fatih Ã–ztel\n",
    "\n",
    "_Student ID:_ 150119907\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9334d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91cf7a6",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0251c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "def error_surface(u, v): # error surface function that give in question\n",
    "    return ((u* (np.exp(v) ) )-( 2 * v * (np.exp(-u))))**2 \n",
    "     \n",
    "def partial_u(u, v): # partial derivative u of error surface on \n",
    "    return 2 * (np.exp(v) + 2*v*(np.exp(-u))) * ( u*(np.exp(v)) - 2 * v *(np.exp(-u)))\n",
    "def partial_v(u, v): # partial derivative u of error surface on \n",
    "    return 2 * ( u * ( np.exp(v)) - 2* (np.exp(-u)) )  * ( u*(np.exp(v)) - 2 * v *(np.exp(-u)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127886a5",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368ce87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, v = 1, 1\n",
    "e = error_surface(u, v) # initial error surface\n",
    "counter = 0\n",
    "while e >= 1e-14: # get out when smaller than 1e-14\n",
    "    u,v = u - learning_rate * partial_u(u, v), v- learning_rate *partial_v(u, v) # updatingu and v -> gradient descent formula\n",
    "    e =  error_surface(u, v) # find new error with new u and v\n",
    "    counter += 1\n",
    "counter #answer is 10 D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14074ce",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a548a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04473629039778207, 0.023958714099141746)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, v # which is very close to E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a66f93",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9094c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13981379199615315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, v = 1, 1\n",
    "e = error_surface(u, v)\n",
    "counter=  0\n",
    "while counter<15: # for 15 iteration\n",
    "    new_u = u - learning_rate * partial_u(u, v) # first update and get new u \n",
    "    u = new_u\n",
    "    new_v = v - learning_rate * partial_v(u, v)  # update v with new u\n",
    "    v = new_v\n",
    "    e =  error_surface(u, v) # find error surface\n",
    "    counter+=1 \n",
    "e # answer is close to 10^-1 which is A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68d1c1",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede866e9",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c23e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0990123109645455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def target_line(): # targe tine function that generates 2 points \n",
    "    target = np.random.uniform(-1,1, size=4).reshape(2,2)\n",
    "    return target\n",
    "def find_boundary(p_x,p_y, line): # function to find boundary of points\n",
    "    # formula to find is point above or belove the target function\n",
    "    det = (line[0][1] - line[0][0]) * (p_y - line[1][0]) - (line[1][1]-line[1][0]) * (p_x-line[0][0]) \n",
    "    return 1 if det > 0 else -1\n",
    "\n",
    "\n",
    "eout_list = [] # list of eouts\n",
    "epoch_list =[] # number of epochs for every iteration\n",
    "for i in range(100):\n",
    "    dataset = np.insert(np.random.uniform(-1,1, size=100*2).reshape(100,2),0,1,axis=1) # generate random train dataset\n",
    "    plane = target_line() # target line \n",
    "    wt_1 = np.zeros(3) # weight for previos epoch first intialize to zero\n",
    "    sign_list=[] # sign list for train data\n",
    "    sign_indexes = np.arange(len(dataset)) # list to represent dataset as indicies\n",
    "    for i in range(len(dataset)): # addi signs for every point\n",
    "        sign_list.append(find_boundary(dataset[i][1],dataset[i][2],plane))\n",
    "\n",
    "\n",
    "    test_set = np.insert(np.random.uniform(-1,1, size=100*2).reshape(100,2),0,1,axis=1) # generate random test set\n",
    "    test_sign_list=[] # test sign list\n",
    "    for i in range(len(test_set)): #\n",
    "        test_sign_list.append(find_boundary(test_set[i][1],test_set[i][2],plane))\n",
    "\n",
    "    e_c = 0; # epoch counter\n",
    "    weight_e = np.zeros(3) #weight for current epoch first intialize zero\n",
    "    while True:\n",
    "        np.random.shuffle(sign_indexes) # shuffle randomly the indices \n",
    "        for i in range(len(sign_indexes)): # update weight_e with every data point \n",
    "            yn = sign_list[sign_indexes[i]] # label of that point\n",
    "            xn = dataset[sign_indexes[i]] # point itself\n",
    "            err_in = - (yn * xn) / (1 + np.exp( yn * np.dot(weight_e,xn) )) # finding err in from formula\n",
    "            weight_e = weight_e - 0.01 * err_in # find new weight \n",
    "        e_c += 1 # increment counter\n",
    "        if  np.linalg.norm(wt_1 - weight_e)  < 0.01: # find l2 norm and check if its smaller \n",
    "            wt_1= weight_e # update previous epoch weight\n",
    "            break\n",
    "        wt_1= weight_e # update previous epoch weight\n",
    "\n",
    "    e_out = np.log( 1 + np.exp(-1 * np.array(test_sign_list) * np.matmul(wt_1,test_set.T)))  # find e out using test set with weight\n",
    "    # np.dot(weight_e.reshape(1,-1), dataset.T)\n",
    "    eout_list.append(np.average(e_out)) # add e out to list \n",
    "    epoch_list.append(e_c) # add epoch counter for that iteration\n",
    "    \n",
    "np.average(np.array(eout_list)) # answer is close to 0.1 so D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74734cc7",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56e5367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347.27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.array(epoch_list)) # answer is close to 350 so A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9cc39",
   "metadata": {},
   "source": [
    "## Regularization with weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93c0e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dta = np.loadtxt(\"in.dta.txt\") # read data\n",
    "out_dta = np.loadtxt(\"out.dta.txt\")\n",
    "in_data, in_label = in_dta[:,:2], in_dta[:,2] # parse the data relativly\n",
    "out_data, out_label = out_dta[:,:2], out_dta[:,2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d63642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_transform(dataset): # apply related nonlinear transform to given dataset\n",
    "    x1_square = (dataset[:,1]**2).reshape(len(dataset),1) # taking square of x1 column\n",
    "    x2_square = (dataset[:,2]**2).reshape(len(dataset),1) # taking square of x2 column\n",
    "    x1_x2 = (dataset[:, 1]* dataset[:, 2]).reshape(len(dataset),1) # multipliying x1 and c2 element wise \n",
    "    x1x2_abs = (np.absolute(dataset[:, 1]- dataset[:, 2])).reshape(len(dataset),1) # | x1-x2|\n",
    "    x1x2_add = (np.absolute(dataset[:, 1] + dataset[:, 2])).reshape(len(dataset),1)#|x1+x2|\n",
    "    dataset = np.concatenate((dataset,x1_square,x2_square,x1_x2,x1x2_abs,x1x2_add), axis=1) # adding created coulmns to dataset \n",
    "    return dataset\n",
    "\n",
    "def linear_regression(dataset, sign_list):# linear regresssion operation \n",
    "    # findind  inverse of x, numpy provides builtin function pinv\n",
    "    x_pseudo = np.linalg.pinv(dataset)\n",
    "    # finding new vector based on linear regression formula \n",
    "    weight = np.matmul(x_pseudo, sign_list) # w = X_inv y\n",
    "    return weight \n",
    "\n",
    "def run_linreg(train_set, train_label,test_set,test_label): # function to run linear regression\n",
    "    weight = linear_regression(train_set, train_label) # finding weight \n",
    "    predict_train = np.sign(np.matmul(weight, train_set.T))  # get prediction from formula matrix multiplication weight with label\n",
    "    predict_test = np.sign(np.matmul(weight, test_set.T)) # get prediction from formula matrix multiplication weight with label\n",
    "    return predict_train, predict_test\n",
    "\n",
    "def find_ein_eout(p_train, p_test): # find ein and eout \n",
    "    miss_train = 0\n",
    "    for i in range(len(p_train)): # counts miss signs\n",
    "        if int(p_train[i]) != int(in_label[i]):miss_train+=1\n",
    "    miss_predict = 0\n",
    "    for i in range(len(p_test)): # counts miss signs\n",
    "        if int(p_test[i]) != int(out_label[i]):miss_predict+=1\n",
    "    return miss_train / len(p_train), miss_predict / len(p_test)\n",
    "\n",
    "\n",
    "nonlin_train = nonlinear_transform(np.insert(in_data,0,1,axis=1)) # transform train data with nonlinear\n",
    "nonlin_test = nonlinear_transform(np.insert(out_data,0,1,axis=1)) # transform test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f9b94",
   "metadata": {},
   "source": [
    "### Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f37e002f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02857142857142857, 0.084)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "p_train, p_test = run_linreg(nonlin_train, in_label,nonlin_test, out_label)\n",
    "\n",
    "find_ein_eout(p_train, p_test) # answers are close to 0.03 and 0.08, A \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f17d9",
   "metadata": {},
   "source": [
    "### Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b3e1f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02857142857142857, 0.08)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_regression_with_weight(dataset, sign_list, k):\n",
    "    # apply linear regression weight function wit weight decay\n",
    "    inverse = np.linalg.inv( np.dot(dataset, dataset.T) + 10**k * np.identity(len(dataset)) )\n",
    "    # finding new vector based on linear regression formula \n",
    "    tmp = np.matmul(inverse, dataset) \n",
    "    weight = np.matmul(tmp.T, sign_list) # final weight with weight\n",
    "    return weight\n",
    "def run_linreg_weight(train_set, train_label,test_set,test_label,k):\n",
    "    weight = linear_regression_with_weight(train_set, train_label,k) # finding weight \n",
    "    predict_train = np.sign(np.matmul(weight, train_set.T))  # train set prediction \n",
    "    predict_test = np.sign(np.matmul(weight, test_set.T)) # test set prediction\n",
    "    return predict_train, predict_test\n",
    "\n",
    "pw_train, pw_test = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, -3)\n",
    "find_ein_eout(pw_train,pw_test) # answer is close to 0.03 and 0.08, D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0577482",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a309e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37142857142857144, 0.436)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_train, pw_test = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, 3)\n",
    "find_ein_eout(pw_train,pw_test) # answer is close to 0.4 and 0.4, E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c703dbb",
   "metadata": {},
   "source": [
    "### Question 5 & 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad717f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.228, 0.124, 0.092, 0.056, 0.084)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_train2, pw_test2 = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, 2)\n",
    "pw_train1, pw_test1 = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, 1)\n",
    "pw_train0, pw_test0 = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, 0)\n",
    "pw_train1n, pw_test1n = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, -1)\n",
    "pw_train2n, pw_test2n = run_linreg_weight(nonlin_train, in_label,nonlin_test, out_label, -2)\n",
    "(find_ein_eout(pw_train2,pw_test2)[1] ,\n",
    "find_ein_eout(pw_train1,pw_test1)[1],\n",
    "find_ein_eout(pw_train0,pw_test0)[1],\n",
    " find_ein_eout(pw_train1n,pw_test1n)[1],\n",
    " find_ein_eout(pw_train2n,pw_test2n)[1],\n",
    ") # when k=-1, the out of sample error is the smallest, D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6199da1",
   "metadata": {},
   "source": [
    "The smallest is 0.056 so, it is closer to 0.06, Answer for Q6 is B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263dc2b",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d1c46",
   "metadata": {},
   "source": [
    "### Question 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8825b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total weights 110\n",
      "total weights 149\n",
      "total weights 186\n",
      "total weights 221\n",
      "total weights 254\n",
      "total weights 285\n",
      "total weights 314\n",
      "total weights 341\n",
      "total weights 366\n",
      "total weights 389\n",
      "total weights 410\n",
      "total weights 429\n",
      "total weights 446\n",
      "total weights 461\n",
      "total weights 474\n",
      "total weights 485\n",
      "total weights 494\n",
      "total weights 501\n",
      "total weights 506\n",
      "total weights 509\n",
      "total weights 510\n",
      "total weights 509\n",
      "total weights 506\n",
      "total weights 501\n",
      "total weights 494\n",
      "total weights 485\n",
      "total weights 474\n",
      "total weights 461\n",
      "total weights 446\n",
      "total weights 429\n",
      "total weights 410\n",
      "total weights 389\n",
      "Maximum is 510\n"
     ]
    }
   ],
   "source": [
    "hidden_units = 36\n",
    "max_w = 0 # to set maximum into this variable \n",
    "for unit_l1 in range(2, 34):\n",
    "    unit_l2 = hidden_units - unit_l1 # number of layer 2 unit\n",
    "    num_w = 0 # first intialize number weight to 0\n",
    "    num_w += ( unit_l1 - 1) * 10 #  input layer to layer 1\n",
    "    num_w +=  ( unit_l2 - 1 ) * unit_l1 # layer 1 to layer 2\n",
    "    num_w += 1 * unit_l2 # layer 2 to output\n",
    "    if num_w > max_w:max_w = num_w\n",
    "    print( \"total weights\", num_w)\n",
    "print( \"Maximum is\", max_w ) # answer is 510, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171b824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
