{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68ec115",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "_Author:_ Muhammed Fatih Ã–ztel\n",
    "\n",
    "_ID:_ 150119907\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0319361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb916ac1",
   "metadata": {},
   "source": [
    "# SVM with Soft Margins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b3f8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"features.train.txt\") # load train and test data with numpy\n",
    "test_data = np.loadtxt(\"features.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe3949",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1169d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.10588396653408312, 0)\n"
     ]
    }
   ],
   "source": [
    "def nVSall(n, dataset):\n",
    "    isN = dataset[:,0] == n # get the related labeled samples as true\n",
    "    X = dataset.copy() # get a copy\n",
    "    X[:,0] = 1.0 # set the first colums as 1 like a bias\n",
    "    y = 2*isN - 1 # set -1 if it is not n if is n let it be 1\n",
    "    return X, y # retrun the x and y label\n",
    "final_ein2=[]\n",
    "l_2 = [0,2,4,6,8] \n",
    "for n in l_2: # for related ns \n",
    "    clf = svm.SVC(C=0.01, kernel=\"poly\", degree=2, gamma=1.0) # set svm model with related parameters\n",
    "    X, y = nVSall(n,train_data) # get related x and y\n",
    "    clf.fit(X, y) # fit this data into svm \n",
    "    predicted_y = clf.predict(X) # make prediction to find e in\n",
    "    ein = np.mean(y != predicted_y) # get average while comparing the predicts and the related label\n",
    "    final_ein2.append((ein, n)) # print out the n and the related e in\n",
    "print(max(final_ein2))\n",
    "# 0 has the maximun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96900e",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47bf5665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.014401316691811822, 1)\n"
     ]
    }
   ],
   "source": [
    "# same functionality with question 2 just numbers of list are changed\n",
    "final_ein3=[]\n",
    "l_3 = [1,3,5,7,9]\n",
    "for n in l_3: \n",
    "    clf = svm.SVC(C=0.01, kernel=\"poly\", degree=2, gamma=1.0)\n",
    "    X, y = nVSall(n,train_data)\n",
    "    clf.fit(X, y)\n",
    "    predicted_y = clf.predict(X)\n",
    "    E_in = np.mean(y != predicted_y)\n",
    "    final_ein3.append((E_in,n))\n",
    "    \n",
    "# 1 has the minimum\n",
    "print(min(final_ein3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c67c2",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2da3a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1793"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs=[] # list to store classifiers\n",
    "for n in [0,1]: # list for answers of q2 and q3\n",
    "    clf = svm.SVC(C=0.01, kernel=\"poly\", degree=2, gamma=1.0) \n",
    "    X, y = nVSall(n,train_data)\n",
    "    clf.fit(X, y)\n",
    "    predicted_y = clf.predict(X)\n",
    "    clfs.append(clf) # append related clf to list\n",
    "len(clfs[0].support_) - len(clfs[1].support_) # get the number of vector and find the difference\n",
    "# which is close to 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67181956",
   "metadata": {},
   "source": [
    "## Question 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd4c6393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| C | Number of vectors | E in | E out |\n",
      "0.001 76 0.004484304932735426 0.01650943396226415\n",
      "0.01 34 0.004484304932735426 0.018867924528301886\n",
      "0.1 24 0.004484304932735426 0.018867924528301886\n",
      "1 24 0.0032030749519538757 0.018867924528301886\n"
     ]
    }
   ],
   "source": [
    "def nVSm(n,m, dataset):\n",
    "    isN = dataset[:,0] == n # to find which is n \n",
    "    isMm = dataset[:,0] == m # to find which is m\n",
    "    data_related = dataset[isN|isMm] # related indices of n and ms \n",
    "    X = data_related.copy() # get a copy of related indices for n and m\n",
    "    X[:,0] = 1.0 # set first column as 1\n",
    "    y = data_related[:,0].copy() \n",
    "    \n",
    "    y[np.where(data_related[:,0] == n)] = 1 # set 1 where class is n\n",
    "    y[np.where(data_related[:,0] == m)] = -1 # set -1 if m\n",
    "    return X, y\n",
    "\n",
    "Cs=[0.001, 0.01, 0.1, 1] # related C values for question\n",
    "\n",
    "train_x, train_y = nVSm(1,5,train_data) # train dataset and label\n",
    "test_x, test_y = nVSm(1,5,test_data) # test dataset\n",
    "print(\"| C | Number of vectors | E in | E out |\") # print statement to see how values are displayed\n",
    "for c in Cs:\n",
    "    clf = svm.SVC(C=c, kernel=\"poly\", degree=2, gamma=1.0) # set classifier with related parameter\n",
    "    clf.fit(train_x, train_y)# fit data into classifier\n",
    "    ein = np.mean(clf.predict(train_x) != train_y) # find E_in\n",
    "    eout = np.mean(clf.predict(test_x) != test_y) # Find E_out\n",
    "    num_sv= len(clf.support_) # get number of support vectors\n",
    "    print(c, num_sv, ein, eout)\n",
    "# Maxiumum C achieves lowest Ein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a6c3c",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c046d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0.0001 v2:236  Ein2:0.008968609865470852 Eout2:0.01650943396226415\n",
      "\tv5:26  Ein5:0.004484304932735426  Eout5:0.018867924528301886 \n",
      "---------------------------------------------------------------------------\n",
      "c:0.001 v2:76  Ein2:0.004484304932735426 Eout2:0.01650943396226415\n",
      "\tv5:25  Ein5:0.004484304932735426  Eout5:0.02122641509433962 \n",
      "---------------------------------------------------------------------------\n",
      "c:0.01 v2:34  Ein2:0.004484304932735426 Eout2:0.018867924528301886\n",
      "\tv5:23  Ein5:0.003843689942344651  Eout5:0.02122641509433962 \n",
      "---------------------------------------------------------------------------\n",
      "c:1 v2:24  Ein2:0.0032030749519538757 Eout2:0.018867924528301886\n",
      "\tv5:21  Ein5:0.0032030749519538757  Eout5:0.02122641509433962 \n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = nVSm(1,5,train_data) # train dataset and label\n",
    "test_x, test_y = nVSm(1,5,test_data) # test dataset\n",
    "for c in (0.0001, 0.001, 0.01, 1):\n",
    "    clf2 = svm.SVC(C=c, kernel=\"poly\", degree=2, gamma=1.0)# set classifier with related parameter with degree 2\n",
    "    clf2.fit(train_x, train_y) # fit data into classifier\n",
    "    ein2 = np.mean(clf2.predict(train_x) != train_y) # find E_in\n",
    "    eout2 = np.mean(clf2.predict(test_x) != test_y) # Find E_out\n",
    "    num_sv2= len(clf2.support_)# get number of support vectors\n",
    "    \n",
    "    clf5 = svm.SVC(C=c, kernel=\"poly\", degree=5, gamma=1.0)# set classifier with related parameter with degree 5\n",
    "    clf5.fit(train_x, train_y)\n",
    "    ein5 = np.mean(clf5.predict(train_x) != train_y)\n",
    "    eout5 = np.mean(clf5.predict(test_x) != test_y)\n",
    "    num_sv5= len(clf5.support_)\n",
    "    print(\"c:{} v2:{}  Ein2:{} Eout2:{}\\n\\tv5:{}  Ein5:{}  Eout5:{} \".format(c,num_sv2,ein2,eout2,num_sv5,ein5,eout5))\n",
    "    print(\"-\"*75)\n",
    "# When C = 0.001, the number of support vectors is lower at Q = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e743180",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ad6f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "X, y = nVSm(1, 5, train_data) # get related x and y labels \n",
    "\n",
    "def find_min(d):# function that returns the better validation error\n",
    "    tmp_min = 9999\n",
    "    arg = 0\n",
    "    for c in (0.0001, 0.001, 0.01, 0.1, 1):\n",
    "        if d[c] < tmp_min:\n",
    "            tmp_min = d[c]\n",
    "            arg = c\n",
    "    return arg\n",
    "\n",
    "selected = {} # dictionary to store number of  selected c values \n",
    "winning_E_cvs = [] # list to store validation errors for c values in each run\n",
    "for i in range(100): # as question wants \n",
    "    kfold = sk.model_selection.KFold(n_splits=10, shuffle=True) # scikit splits into 10 fold and shuffled\n",
    "    ecvs = {} # to store validation errors for related c values and for each fold\n",
    "    for itrain, itest in kfold.split(X): # iteareting folds\n",
    "        for c in [0.0001, 0.001, 0.01, 0.1, 1]: # iterating for different c values\n",
    "            ecvs.setdefault(c,0)\n",
    "            train_x, train_y = X[itrain,:], y[itrain] # get traing data \n",
    "            test_x, test_y = X[itest,:], y[itest] # get test data\n",
    "            clf = svm.SVC(C=c, kernel=\"poly\", degree=2, gamma=1.0) # create SVM object \n",
    "            clf.fit(train_x, train_y) # fit related data \n",
    "            e_val = np.mean(clf.predict(test_x) != test_y) # get validation error \n",
    "            ecvs[c] += e_val # add error into related c values then we will get average\n",
    "    best_c = find_min(ecvs)  # find which c has lowest \n",
    "    selected.setdefault(best_c,0) # set the keys value to 0 if its not exist\n",
    "    selected[best_c] += 1 # add 1 to selected c\n",
    "    winning_E_cvs.append(ecvs[best_c]/10) # add best cv error into list for this iteration with taking the average\n",
    "print(max(selected, key=selected.get))\n",
    "# 0.001 is selected most often, Answer B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb48c1",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3f2355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004452678425608361\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(winning_E_cvs))\n",
    "# Answer is close to 0.005, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c097a97",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "956c45ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0006406149903907751, 1000000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = nVSm(1,5,train_data) # train dataset and label\n",
    "test_x, test_y = nVSm(1,5,test_data) # test dataset\n",
    "q9cs=[0.01,  1,  100, 10**4,10**6]\n",
    "all_ein,all_eout=[],[]\n",
    "for c in q9cs:\n",
    "    clf = svm.SVC(C=c, kernel=\"rbf\", degree=2, gamma=1.0) # set svm fernel as rbf \n",
    "    clf.fit(train_x, train_y) # fit the data\n",
    "    ein = np.mean(clf.predict(train_x) != train_y) # find the ein\n",
    "    eout = np.mean(clf.predict(test_x) != test_y) # find the eout\n",
    "    all_ein.append((ein, c)) # add to the list\n",
    "    all_eout.append((eout, c)) # add to the list\n",
    "min(all_ein) \n",
    "#10^6 has the lowest e in so C,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b902ae",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "965941d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.018867924528301886, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  100 is the lowest for e out\n",
    "min(all_eout)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
