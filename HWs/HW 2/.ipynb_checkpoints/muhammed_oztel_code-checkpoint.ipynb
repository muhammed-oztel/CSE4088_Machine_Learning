{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "_Author:_ Muhammed Fatih Ã–ztel\n",
    "\n",
    "_ID:_ 150119907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# requrierd librares\n",
    "# numpy\n",
    "# random\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#     Inputs: None\n",
    "#     Output: \n",
    "#         - target: numpy array of 2 points which represent xs and ys of randomly generated points  \n",
    "\n",
    "    # Target function cretaes a function line which passes from -1 to 1\n",
    "def target_function(): \n",
    "    # generate random 4 points and reshaping it to work easily\n",
    "    target = np.random.uniform(-1,1, size=4).reshape(2,2)\n",
    "    return target\n",
    "\n",
    "#     Inputs: \n",
    "#         - p_x: x value of the point, a number\n",
    "#         - p_y: y value of the point, a number\n",
    "#         - line: target line, list of 2 points\n",
    "#     Outout: \n",
    "#         1 or -1 : represents where the point is\n",
    "#     Function to find if point is above or belove the target function\n",
    "def find_boundary(p_x,p_y, line):\n",
    "    # formula to find is point above or belove the target function\n",
    "    det = (line[0][1] - line[0][0]) * (p_y - line[1][0]) - (line[1][1]-line[1][0]) * (p_x-line[0][0]) \n",
    "    return 1 if det > 0 else -1\n",
    "\n",
    "\n",
    "\n",
    "#     Inputs: \n",
    "#         - weight: weight vector for PLA, array\n",
    "#         - inserted: list of dataset with w_0 inserted at each element to make related calculation\n",
    "#         - sign_list: list of sign of points\n",
    "#     Output: \n",
    "#         -missclassified: list of points which are missclassified\n",
    "#     Function to return missclassified points \n",
    "def find_missclassified(weight,inserted, sign_list):\n",
    "    # declareing an empty list to add missclassified points\n",
    "    missclassified = []\n",
    "    # checking every point in dataset whether it is correctly classified or not\n",
    "    for i in range(len(inserted)):\n",
    "        # matrice multiplication with weight and point to find where the point stands\n",
    "        product = np.matmul(weight, inserted[i]) \n",
    "        g_sign = 0 \n",
    "        if product<0:g_sign = -1\n",
    "        elif product>0:g_sign= 1\n",
    "        # checking whether the point is correctly classified or not\n",
    "        # if not add to miss list\n",
    "        if sign_list[i] !=g_sign:\n",
    "            missclassified.append(i)\n",
    "    return missclassified\n",
    "    \n",
    "#     Inputs:\n",
    "#         - weight: weight vector from PLA, an array\n",
    "#         - inserted:list of dataset with w_0 inserted at each element to make related calculation\n",
    "#         - line: target line, list of 2 points\n",
    "#         - sign_list: list of sign of points\n",
    "#     Output: \n",
    "#         - counter: a number to find how man miss occured while converging\n",
    "#     Description: Function that counts until the weight converges to target, PLA algorithm\n",
    "def perceptron_la(weight, inserted, line, sign_list):\n",
    "    counter = 1\n",
    "    while True:\n",
    "        # Find all missclassified points\n",
    "        missclassified = find_missclassified(weight,inserted, sign_list)\n",
    "        # if there is no missclassified point means its fine, break the loop\n",
    "        if missclassified == []:\n",
    "            break\n",
    "        # take random point from missclassifieds\n",
    "        rand_choice = random.choice(inserted[missclassified])\n",
    "        y_sign = find_boundary(rand_choice[1],rand_choice[2],line) # find where the pooint should be represented\n",
    "        weight += y_sign * rand_choice # update the weight vector based on PLA formula\n",
    "        counter +=1 # increment the counter\n",
    "    return counter\n",
    "\n",
    "\n",
    "#     Inputs: \n",
    "#         - num_of_iters: number of iterations \n",
    "#         - num_of_data: number for dataset size\n",
    "#     Outputs:\n",
    "#         - list_of_counter: list of every counter for how much it took to converge for each converge\n",
    "#         - weight: weight vector of last iteration (to use in 5 and 7th questions)\n",
    "#         - line: target function, list of 2 points (to use in 5 and 7th questions)\n",
    "#     Function to generate dataset points and using PLA find how much it takes to converge\n",
    "def run_with_iter( num_of_iters, num_of_data):\n",
    "    list_of_counters = [] # list to store counter of each PLA iteration \n",
    "    # generating dataset for given time and running PLA\n",
    "    for i in range(num_of_iters):\n",
    "        # create randomly uniform dataset with given dataset size\n",
    "        # reshape in correct point format\n",
    "        dataset = np.random.uniform(-1,1, size=num_of_data*2).reshape(num_of_data,2)\n",
    "        line = target_function() # a target function to use finding  signs\n",
    "        signs_of_dataset = [] # list of sign for each point in dataset\n",
    "        for i in range(len(dataset)): # loop to find sign of dataset points\n",
    "            # adding sign of point based on index\n",
    "            signs_of_dataset.append(find_boundary(dataset[i][0],dataset[i][1],line))\n",
    "        inserted = np.insert(dataset,0,1,axis=1) # inserting one at every point in dataset to make easier calculations 3xN\n",
    "        weight = np.zeros(3) # creating weight of zeros at the begining\n",
    "        count= perceptron_la(weight,inserted, line, signs_of_dataset) # how many iteartion does it take to converge with PLA \n",
    "        list_of_counters.append(count) # add count to list\n",
    "    return list_of_counters, weight, line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.183"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, weight, target_line = (run_with_iter(1000, 10))\n",
    "np.average(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21538300000000002"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     Input:\n",
    "#         - num_of_iters: number of iterations \n",
    "#         - num_of_data: number for dataset size\n",
    "#         - weight: weight vector of last iteration \n",
    "#         - line: target function, list of 2 points \n",
    "#     Output:\n",
    "#         average number of miss probability\n",
    "#     Description: Finds the probability error\n",
    "\n",
    "def find_error( num_of_iters, num_of_fresh, weight, line ):\n",
    "    fresh_probs = [] # list of probability of newly created point\n",
    "    # loop for generating N times\n",
    "    for i in range(num_of_iters):\n",
    "        # generate new points to check with target function and weight of last run\n",
    "        fresh_points = np.insert(np.random.uniform(-1,1, size=num_of_fresh*2).reshape(num_of_fresh,2),0,1,axis=1)\n",
    "        signs_of_fresh = [] # list of new point signs\n",
    "        for i in range(len(fresh_points)): # iterating over every point to find sign and add to list\n",
    "            signs_of_fresh.append(find_boundary(fresh_points[i][1],fresh_points[i][2],line))\n",
    "        predict = np.sign(np.matmul(weight, fresh_points.T)) # checking if the prediction is correct with matrice multiplication\n",
    "\n",
    "        miss_count = 0\n",
    "        for i in range(len(predict)): # counting how many miss predictions occured\n",
    "            if int(predict[i]) != int(signs_of_fresh[i]):miss_count+=1\n",
    "        fresh_probs.append(miss_count / len(fresh_points)) # ratio of miss over size of dataset\n",
    "    return np.average(fresh_probs) # average of final predictions\n",
    "# close to 0.1 so answer is C\n",
    "find_error(1000,1000,weight, target_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131.866"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it may take longer to process this cell. For my test system it takes 24 seconds at average\n",
    "result, weight, target_line = (run_with_iter(1000, 100))\n",
    "np.average(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011798000000000001"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_error(1000,1000, weight,target_line) # running same function used in q5 with new weight and targe line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Linear regression function takes 2 input \n",
    "#     list of dataset with inserted 1\n",
    "#     list of point signs\n",
    "# outputs:\n",
    "#     ratio of misses on dataset size\n",
    "#     weight vector\n",
    "# this function evaluates linear regression. takes pseduo inverse of x and do matrice multiplication\n",
    "# to find new weight and return num of each misses\n",
    "def linear_regression(inserted, sign_list):\n",
    "    # findind pseudo inverse of x, numpy provides builtin function pinv\n",
    "    x_pseudo = np.linalg.pinv(inserted)\n",
    "    # finding new vector based on linear regression formula \n",
    "    weight = np.matmul(x_pseudo, sign_list) # w = X_inv y\n",
    "    predict = np.sign(np.matmul(weight, inserted.T))  # finding how new weight classifies the points\n",
    "    miss_count = 0\n",
    "    for i in range(len(predict)): # checking if new classified signes are same with real classifications\n",
    "        if int(predict[i]) != sign_list[i]:miss_count+=1\n",
    "    return miss_count*1.0 / len(predict) ,weight # returning the ratio of miss over dataset len\n",
    "\n",
    "\n",
    "# funtion to run multiple iterations of linear regression and generating dataset with given number\n",
    "# 2 inputs \n",
    "# num_of_iters: how many times to test the algorithm\n",
    "# data_size: number of data point in one set\n",
    "# outputs: \n",
    "# list of probability/ratio of miss and weight vector  \n",
    "def run_linreg_with_iter(num_of_iters, data_size):\n",
    "    list_of_probs = [] # to store every iterations miss probabilities\n",
    "    for i in range(num_of_iters):# doing this procedure many times \n",
    "        # generate a dataset \n",
    "        dataset = np.random.uniform(-1,1, size=data_size*2).reshape(data_size,2)\n",
    "        line = target_function() # target function\n",
    "        signs_of_dataset = [] # list of sign of every point in dataset\n",
    "        for i in range(len(dataset)): # iterating over every point and calssify their zone\n",
    "            signs_of_dataset.append(find_boundary(dataset[i][0],dataset[i][1],line))# adding to list\n",
    "        inserted = np.insert(dataset,0,1,axis=1) #inserting 1 to the begining of every element  \n",
    "        count, weight = linear_regression(inserted, signs_of_dataset) # finding weight and average of miss\n",
    "        list_of_probs.append(count) # adding to list\n",
    "    return np.average(list_of_probs), line, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03869"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. c  Close to 0.01\n",
    "result,line8,weight8 = (run_linreg_with_iter(1000, 100))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03229800000000001"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     Input:\n",
    "#         - num_of_iters: number of iterations \n",
    "#         - num_of_data: number for dataset size\n",
    "#         - weight: weight vector of last iteration \n",
    "#         - line: target function, list of 2 points \n",
    "#     Output:\n",
    "#         average number of miss probability\n",
    "#     Description: Finds the probability error\n",
    "\n",
    "def test_with_fresh(line, weight, num_of_iter, num_of_fresh):\n",
    "    fresh_probs = []# list of probability of newly created point\n",
    "    for i in range( num_of_iter ):\n",
    "        # generate new points to check with target function and weight of last run\n",
    "        fresh_points = np.insert(np.random.uniform(-1,1, size=num_of_fresh*2).reshape(num_of_fresh,2),0,1,axis=1)\n",
    "\n",
    "        signs_of_fresh = []# list of new point signs\n",
    "        for i in range(len(fresh_points)):# iterating over every point to find sign and add to list\n",
    "            signs_of_fresh.append(find_boundary(fresh_points[i][1],fresh_points[i][2],line))\n",
    "        predict = np.sign(np.matmul(weight, fresh_points.T)) # get n ew predictions\n",
    "\n",
    "        miss_count = 0\n",
    "        for i in range(len(predict)):# find how many counts appeared\n",
    "            if int(predict[i]) != int(signs_of_fresh[i]):miss_count+=1\n",
    "        fresh_probs.append(miss_count / len(fresh_points)) # divide miss cont with dataset size\n",
    "\n",
    "\n",
    "    return np.average(fresh_probs)\n",
    "# close to 0.01 answer C\n",
    "test_with_fresh(line8,weight8, 1000,1000) # giving weight and target from question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.472"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting weight with sample N=10\n",
    "result, line, weight = (run_linreg_with_iter(1000, 10)) \n",
    "pla_counts = [] # list to store how many iter takes it to converge\n",
    "for i in range(1000):\n",
    "    dataset = np.insert(np.random.uniform(-1,1, size=10*2).reshape(10,2),0,1,axis=1) # generate dataset\n",
    "    sign_list=[]\n",
    "    for i in range(len(dataset)): #\n",
    "        sign_list.append(find_boundary(dataset[i][1],dataset[i][2],line))\n",
    "    count= perceptron_la(weight, dataset, line, sign_list) # giving previoes weight to pla and see how long it takes\n",
    "    pla_counts.append(count) # add counter to list \n",
    "np.average(pla_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Non Linear Transformation\n",
    "\n",
    "## Question 11 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5063869999999999"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to set sign of points based on nonlinear defiition function\n",
    "# takes 2 input x1 and x2\n",
    "# returns  1 if above 0 otherwise -1\n",
    "def nonlinear_target(x1, x2):\n",
    "    return  1 if (x1**2 + x2**2 - 0.6) > 0 else -1\n",
    "\n",
    "\n",
    "# function to run 1000 times nonlinar function for question eleven\n",
    "# generates a training dataset with 1000 input\n",
    "# flips %10 of signs to create noise\n",
    "# checking the sample error \n",
    "def nonlin_simple():\n",
    "    list_of_counts = [] # list to store \n",
    "    for i in range(1000): # itearet  1000 times\n",
    "        training_set =  np.random.uniform(-1,1, size=1000*2).reshape(1000, 2) # create training dataset \n",
    "        flipped_sign= [] # list of sign %10 percent of points are flipped\n",
    "        for i in range(len(training_set)): # \n",
    "            sign = nonlinear_target(training_set[i][0],training_set[i][1]) # with nonliear target function\n",
    "            if i %10 == 0:sign=-1*sign # for every ten element 1 the sign flipped \n",
    "            flipped_sign.append(sign) # add to list\n",
    "        inserted = np.insert(training_set,0,1,axis=1) # inserting 1 so make matrice multiplication easier\n",
    "        # get the linear predictions based on nonlinearly flipped signs\n",
    "        count, weight = linear_regression(inserted, flipped_sign)\n",
    "        list_of_counts.append(count) # add into list\n",
    "    return np.average(list_of_counts)\n",
    "    \n",
    "# since answer is close to 0.5 answer for q 11 is d \n",
    "nonlin_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True) # to display in scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99222461, -0.0016541 ,  0.00048866, -0.00035067,  1.55923246,\n",
       "        1.55880386])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part for question 12\n",
    "# function returns the average weight with nw weight vector\n",
    "def new_weight():\n",
    "    weight_total= np.zeros(6)\n",
    "    for i in range(1000):\n",
    "        # generating dataset with size of 1000 and also 1 inserted\n",
    "        dataset = np.insert(np.random.uniform(-1,1, size=1000*2).reshape(1000, 2),0,1,axis=1)\n",
    "        # as in question wanted the weight vector has 6 argument (1, x1,x2,x1x2,x1^2,x2^2), so\n",
    "        # need to edit dataset array also\n",
    "        x1_x2 = (dataset[:, 1]* dataset[:, 2]).reshape(1000,1) # multipliying x1 and c2 element wise \n",
    "        x1_square = (dataset[:,1]**2).reshape(1000,1) # taking square of x1 column\n",
    "        x2_square = (dataset[:,2]**2).reshape(1000,1) # taking square of x2 column\n",
    "        dataset = np.concatenate((dataset, x1_x2,x1_square,x2_square), axis=1) # adding created coulmns to dataset \n",
    "        flipped_sign= []\n",
    "        for i in range(len(dataset)): # finding signs and flipping %10 percent of the items\n",
    "            sign = nonlinear_target(dataset[i][1],dataset[i][2])\n",
    "            if i %10 == 0:sign=-1*sign\n",
    "            flipped_sign.append(sign)\n",
    "        count, weight = linear_regression(dataset, flipped_sign) # getting weight\n",
    "        weight_total+=weight\n",
    "    return (weight_total/1000)\n",
    "\n",
    "weight = new_weight()\n",
    "weight # answer is  a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.122763"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# functio to test with fresh points \n",
    "# it takes weight from q12, number of iterations to get average and number of fresh dataset size\n",
    "# generates new points and finds out of sample error based on previos weight \n",
    "def find_nonlin_err(weight, num_of_iter, num_of_fresh):\n",
    "    fresh_probs = []\n",
    "    for i in range( num_of_iter ):\n",
    "        #generate new set of points \n",
    "        fresh_points = np.insert(np.random.uniform(-1,1, size=num_of_fresh*2).reshape(num_of_fresh,2),0,1,axis=1)\n",
    "        # as in question wanted the weight vector has 6 argument (1, x1,x2,x1x2,x1^2,x2^2), so\n",
    "        # need to edit dataset array also\n",
    "        x1_x2 = (fresh_points[:, 1]* fresh_points[:, 2]).reshape(1000,1) # multipliying x1 and c2 element wise \n",
    "        x1_square = (fresh_points[:,1]**2).reshape(1000,1) # taking square of x1 column\n",
    "        x2_square = (fresh_points[:,2]**2).reshape(1000,1) # taking square of x2 column\n",
    "        fresh_points = np.concatenate((fresh_points, x1_x2,x1_square,x2_square), axis=1)# adding created coulmns to dataset \n",
    "        signs_of_fresh = []\n",
    "        for i in range(len(fresh_points)):# finding signs and flipping %10 percent of the items\n",
    "            sign = nonlinear_target(fresh_points[i][1],fresh_points[i][2])\n",
    "            if i %10 == 0:sign=-1*sign\n",
    "            signs_of_fresh.append(sign)\n",
    "        predict = np.sign(np.matmul(weight, fresh_points.T)) # getting predictions with matrice multiplication\n",
    "\n",
    "        miss_count = 0\n",
    "        for i in range(len(predict)): # counts miss signs\n",
    "            if int(predict[i]) != int(signs_of_fresh[i]):miss_count+=1\n",
    "        fresh_probs.append(miss_count / len(fresh_points))\n",
    "\n",
    "    return np.average(fresh_probs) # return average of out of sample error\n",
    "\n",
    "# answer is close to 0.1 answer b\n",
    "find_nonlin_err(weight, 1000, 1000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81248d4f47741c59d54854640730bc2709090d980144e2f19c3d8319ffea9c3c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
